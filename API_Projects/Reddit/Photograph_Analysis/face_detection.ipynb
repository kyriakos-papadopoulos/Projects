{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609aed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b820e1",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9681c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/Users/kyriakospapadopoulos/Desktop/University/Big Blue Data Academy/Personal/Projects/API_Projects/Reddit/Photograph_Analysis/photographs_top_1000\"\n",
    "df_path = os.path.join(directory, \"face_detection_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff64966",
   "metadata": {},
   "source": [
    "# Face identification with OpenCV’s Haar Cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea2a857",
   "metadata": {},
   "source": [
    "## Summary of OpenCV’s Haar Cascade\n",
    "---\n",
    "**OpenCV’s Haar Cascade** is a popular object detection algorithm that is primarily used for face detection in images and video streams. It is based on the concept of Haar-like features and uses a cascade of classifiers to detect objects in a given image.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **Haar-like Features**:\n",
    "  - **Description**:\n",
    "    - Haar-like features are digital image features used in object recognition. These features are named after the Haar wavelet and are essentially rectangular patterns that represent the contrast between adjacent regions of an image.\n",
    "    - For example, a Haar-like feature could capture the difference in brightness between the eyes and the upper cheeks in a face, or between the bridge of the nose and the eyes.\n",
    "  - **Calculation**:\n",
    "    - The value of a Haar-like feature is calculated by subtracting the sum of pixel values in one rectangular region of the image from the sum of pixel values in another adjacent rectangular region. These rectangular regions can vary in size and position to capture different types of features.\n",
    "    - The algorithm evaluates a large number of these features at different scales and locations in the image to detect objects.\n",
    "  \n",
    "- **Integral Image**:\n",
    "  - **Description**:\n",
    "    - The integral image is a data structure that allows for the rapid calculation of pixel sums over rectangular regions. It is a key component of the Haar Cascade algorithm because it speeds up the computation of Haar-like features.\n",
    "  - **Calculation**:\n",
    "    - The integral image is computed by summing all pixel values above and to the left of a given pixel. This means that the sum of pixel values within any rectangular area of the original image can be calculated in constant time, regardless of the size of the rectangle.\n",
    "    - This efficiency is crucial for real-time object detection, as it allows the algorithm to quickly compute the sum of pixel values over multiple regions at different scales.\n",
    "\n",
    "- **Cascade of Classifiers**:\n",
    "  - **Description**:\n",
    "    - The Haar Cascade algorithm uses a series of classifiers that are arranged in stages, known as a cascade. Each stage contains a number of weak classifiers, which are simple decision rules based on Haar-like features.\n",
    "    - A weak classifier is considered \"weak\" because it alone is not very accurate, but when combined with other weak classifiers in a stage, it contributes to a strong decision-making process.\n",
    "  - **Working**:\n",
    "    - During detection, the algorithm scans the image and evaluates the Haar-like features in a given region. If a region passes through all the stages of the cascade, it is classified as containing the object (e.g., a face). If it fails at any stage, the region is immediately discarded.\n",
    "    - This cascading structure allows the algorithm to quickly eliminate regions of the image that do not contain the object of interest, significantly speeding up the detection process.\n",
    "    - The first stages of the cascade are designed to reject the majority of non-object regions quickly, while later stages become more complex and focus on refining the detection.\n",
    "\n",
    "### What Haar Cascade Does:\n",
    "\n",
    "- **Face Detection**:\n",
    "  - Haar Cascade is most commonly used for detecting faces in images. It is pre-trained on large datasets of face images and can accurately detect faces across different scales and orientations.\n",
    "\n",
    "- **Other Object Detection**:\n",
    "  - While face detection is its primary use, Haar Cascade can also be trained to detect other objects, such as eyes, license plates, and even specific animals. However, the accuracy and performance for these tasks may vary depending on the complexity of the object.\n",
    "\n",
    "- **Real-Time Detection**:\n",
    "  - Due to its efficiency, Haar Cascade can be used for real-time object detection in applications such as video surveillance, facial recognition systems, and interactive user interfaces.\n",
    "\n",
    "### Limitations:\n",
    "\n",
    "- **Sensitivity to Lighting Conditions**:\n",
    "  - Haar Cascade can be sensitive to changes in lighting and may struggle with detecting objects in low-light or overly bright environments.\n",
    "\n",
    "- **Accuracy**:\n",
    "  - While fast, Haar Cascade may not be as accurate as more modern object detection algorithms, especially when it comes to detecting smaller objects or objects with complex backgrounds.\n",
    "\n",
    "- **False Positives**:\n",
    "  - The algorithm may sometimes detect objects that are not present (false positives), especially in cluttered or complex images.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dc56c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect faces using OpenCV's Haar Cascades\n",
    "def detect_face_opencv(image_path):\n",
    "    # Load the pre-trained Haar Cascade classifier for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert the image to grayscale\n",
    "    \n",
    "    # Adjust the scaleFactor and minNeighbors for reduced sensitivity (fewer false positives)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=8)\n",
    "    \n",
    "    # Return True if at least one face is detected, otherwise False\n",
    "    return len(faces) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c4ac21",
   "metadata": {},
   "source": [
    "### 'detect_face_opencv' function breakdown\n",
    "---\n",
    "- **`face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')`**:\n",
    "  - This line loads the pre-trained Haar Cascade classifier for face detection from OpenCV. The `'haarcascade_frontalface_default.xml'` file contains the trained data for detecting frontal faces.\n",
    "\n",
    "- **`image = cv2.imread(image_path)`**:\n",
    "  - The image is read from the specified `image_path` using OpenCV's `cv2.imread` function. The image is loaded as a color image.\n",
    "\n",
    "- **`gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)`**:\n",
    "  - The loaded color image is converted to grayscale using `cv2.cvtColor`. Face detection with Haar Cascades is typically performed on grayscale images because it simplifies the computation and improves performance.\n",
    "\n",
    "- **`faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=8)`**:\n",
    "  - The `detectMultiScale` method is applied to the grayscale image to detect faces. The `scaleFactor` parameter controls how much the image size is reduced at each image scale, and `minNeighbors` specifies how many neighbors each candidate rectangle should have to retain it. A higher `scaleFactor` and `minNeighbors` reduce sensitivity, potentially leading to fewer false positives.\n",
    "\n",
    "- **`return len(faces) > 0`**:\n",
    "  - The function returns `True` if at least one face is detected in the image (i.e., `len(faces)` is greater than 0). If no faces are detected, it returns `False`.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze images and create a new DataFrame with face detection results\n",
    "def analyze_faces_with_opencv(directory, save_interval=100):\n",
    "    # Initialize a new DataFrame\n",
    "    df = pd.DataFrame(columns=['File Name', 'OpenCV’s Haar Cascade results'])\n",
    "        \n",
    "    # Process each image in the directory\n",
    "    for idx, filename in enumerate(tqdm(os.listdir(directory), desc=\"Running OpenCV Face Detection\")):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Adjust based on your file types\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            \n",
    "            if os.path.exists(image_path):\n",
    "                face_detected = detect_face_opencv(image_path)\n",
    "                df = df.append({'File Name': filename, 'OpenCV’s Haar Cascade results': face_detected}, ignore_index=True)\n",
    "            \n",
    "        if idx % save_interval == 0 and idx != 0:\n",
    "            # Save progress periodically\n",
    "            df.to_csv(os.path.join(directory, \"face_detection_results.csv\"), index=False)\n",
    "    \n",
    "    # Save the final updated DataFrame\n",
    "    df.to_csv(os.path.join(directory, \"face_detection_results.csv\"), index=False)\n",
    "    print(\"OpenCV face detection complete. Results saved to face_detection_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb71433",
   "metadata": {},
   "source": [
    "### 'analyze_faces_with_opencv' function breakdown\n",
    "---\n",
    "- **`df = pd.DataFrame(columns=['File Name', 'OpenCV’s Haar Cascade results'])`**:\n",
    "  - This line initializes a new pandas DataFrame with two columns: `'File Name'` to store the name of each image file and `'OpenCV’s Haar Cascade results'` to store the face detection results (True or False).\n",
    "\n",
    "- **Loop through each image in the directory**:\n",
    "  - The function iterates over all files in the specified `directory` using `tqdm` to display a progress bar. The loop processes only files with image extensions such as `.jpg`, `.jpeg`, `.png`, and `.bmp`.\n",
    "\n",
    "- **`image_path = os.path.join(directory, filename)`**:\n",
    "  - For each image file, the full path is constructed by joining the directory path with the filename.\n",
    "\n",
    "- **`if os.path.exists(image_path): face_detected = detect_face_opencv(image_path)`**:\n",
    "  - If the image file exists at the specified path, the function calls `detect_face_opencv(image_path)` to determine if a face is detected in the image. The result (True or False) is returned.\n",
    "\n",
    "- **`df = df.append({'File Name': filename, 'OpenCV’s Haar Cascade results': face_detected}, ignore_index=True)`**:\n",
    "  - The filename and face detection result are appended as a new row to the DataFrame. The `ignore_index=True` parameter ensures that the DataFrame index is reset for each new row.\n",
    "\n",
    "- **Periodically save progress**:\n",
    "  - Every `save_interval` iterations, the current state of the DataFrame is saved to a CSV file (`face_detection_results.csv`) in the specified directory. This ensures that progress is saved periodically, reducing the risk of data loss in case of an interruption.\n",
    "\n",
    "- **Final save**:\n",
    "  - After all images have been processed, the final version of the updated DataFrame is saved to `face_detection_results.csv`. A message is printed to confirm that the OpenCV face detection analysis is complete and the results have been saved.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efef3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_faces_with_opencv(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1111c163",
   "metadata": {},
   "source": [
    "# Portrait identification with Dlib’s HOG + SVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47543ca5",
   "metadata": {},
   "source": [
    "## Summary of Dlib’s HOG + SVM Face Detector\n",
    "---\n",
    "**Dlib’s HOG + SVM Face Detector** is a widely-used method for detecting faces in images. It combines Histogram of Oriented Gradients (HOG) for feature extraction with a Support Vector Machine (SVM) classifier to identify faces. This method is particularly effective in detecting faces with various orientations and under different lighting conditions.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **Histogram of Oriented Gradients (HOG)**:\n",
    "  - **Description**:\n",
    "    - HOG is a feature descriptor used in computer vision to capture the structure and shape of objects within an image. It works by dividing the image into small regions (cells) and computing the gradient direction and magnitude within each cell.\n",
    "  - **Gradient Calculation**:\n",
    "    - The gradient at each pixel is computed by finding the difference in intensity between adjacent pixels. The orientation of the gradient is determined by the direction in which the intensity changes the most.\n",
    "    - These gradients are then binned into orientation histograms, where each bin represents a specific range of angles. The histograms from all cells are concatenated to form a feature vector that describes the overall shape and structure of the object.\n",
    "  - **Robustness**:\n",
    "    - HOG is particularly robust to variations in lighting and small changes in the appearance of the object, making it effective for face detection across different environments.\n",
    "\n",
    "- **Support Vector Machine (SVM)**:\n",
    "  - **Description**:\n",
    "    - SVM is a supervised learning algorithm used for classification tasks. It works by finding the hyperplane that best separates the data points of different classes in a high-dimensional space.\n",
    "  - **Face Classification**:\n",
    "    - In the context of face detection, the SVM classifier is trained on HOG features extracted from face and non-face images. The classifier learns to distinguish between these two classes based on the patterns in the HOG features.\n",
    "    - During detection, the SVM classifier evaluates the HOG features of regions in the image and determines whether they correspond to a face or not.\n",
    "\n",
    "### What Dlib’s HOG + SVM Face Detector Does:\n",
    "\n",
    "- **Face Detection**:\n",
    "  - Dlib’s HOG + SVM face detector is used to identify faces in images. It works well in detecting faces that are front-facing or slightly turned and can handle various lighting conditions.\n",
    "  \n",
    "- **Portrait Detection**:\n",
    "  - This method can be extended to detect portraits by analyzing the proportion of the image occupied by a detected face. A face that takes up a significant portion of the image is likely to be a portrait, which can be useful in filtering and categorizing images based on their content.\n",
    "\n",
    "- **Real-Time Detection**:\n",
    "  - While not as fast as some deep learning-based methods, Dlib’s HOG + SVM detector is efficient enough for real-time applications on reasonably powerful hardware.\n",
    "\n",
    "### Limitations:\n",
    "\n",
    "- **Scale and Orientation Sensitivity**:\n",
    "  - Although Dlib’s HOG + SVM face detector is robust, it may struggle with extreme variations in face orientation or scale. For instance, it may not perform as well on images where faces are at sharp angles or very small relative to the image size.\n",
    "\n",
    "- **Speed**:\n",
    "  - Compared to more modern deep learning methods, Dlib’s HOG + SVM can be slower, especially when processing high-resolution images or large datasets.\n",
    "\n",
    "- **False Positives**:\n",
    "  - Like many face detection algorithms, this method can sometimes produce false positives, detecting faces where none exist.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5032b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the face detector from Dlib\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b096ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect portraits using Dlib's HOG + SVM face detector\n",
    "def detect_portrait_dlib(image_path, face_min_proportion=0.05):\n",
    "    image = io.imread(image_path)\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Detect faces in the image\n",
    "    faces = detector(image, 1)\n",
    "    \n",
    "    for face in faces:\n",
    "        # Calculate the area of the detected face\n",
    "        face_area = (face.right() - face.left()) * (face.bottom() - face.top())\n",
    "        image_area = height * width\n",
    "        \n",
    "        # Check if the face occupies a significant portion of the image (portrait)\n",
    "        if face_area / image_area >= face_min_proportion:\n",
    "            return True  # Considered a portrait\n",
    "    \n",
    "    return False  # No face or insignificant face size detected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992bdc3c",
   "metadata": {},
   "source": [
    "### 'detect_portrait_dlib' function breakdown\n",
    "---\n",
    "- **`image_path`**: This parameter represents the file path of the image that will be analyzed.\n",
    "- **`face_min_proportion`**: This optional parameter specifies the minimum proportion of the image's area that a detected face must occupy to be considered a portrait. The default value is `0.05`, meaning the face must occupy at least 5% of the total image area to be considered a portrait.\n",
    "- **`io.imread(image_path)`**: This line loads the image from the specified file path using `io.imread`, typically from the `skimage` library. The image is loaded as an array of pixel values.\n",
    "- **`image.shape[:2]`**: The shape of the image array is used to extract the height and width of the image. These dimensions are needed to calculate the total area of the image and to determine the relative size of any detected faces.\n",
    "- **`detector(image, 1)`**: This line applies Dlib's face detector to the loaded image. The `1` parameter indicates that the image should be upsampled once before detection, which can help in detecting smaller faces. The `detector` function returns a list of detected faces, where each face is represented by a bounding box.\n",
    "- **Loop**: The function iterates over each detected face in the `faces` list. For each face, the area is calculated to determine if it qualifies as a portrait.\n",
    "    - **`face_area`**: The area of the detected face is calculated using the coordinates of the bounding box around the face. `face.right()` and `face.left()` give the x-coordinates of the right and left edges of the bounding box, while `face.bottom()` and `face.top()` give the y-coordinates of the bottom and top edges.\n",
    "    - **`image_area`**: The total area of the image is calculated by multiplying its height by its width.\n",
    "    - **Proportion Check**: The function checks whether the detected face occupies at least the specified proportion of the image area (`face_min_proportion`). If it does, the function returns `True`, indicating that the image contains a portrait.\n",
    "- **Return False**: If no face meets the minimum size requirement, the function returns `False`, indicating that the image does not contain a portrait.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ae650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze images and update the DataFrame with portrait detection results\n",
    "def analyze_portraits_with_dlib(directory, df_path, save_interval=100):\n",
    "    # Load the existing DataFrame\n",
    "    if os.path.exists(df_path):\n",
    "        df = pd.read_csv(df_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"The specified DataFrame file does not exist: {df_path}\")\n",
    "\n",
    "    # Add a new column for portrait detection results if it doesn't exist\n",
    "    if 'Dlib’s HOG + SVM results' not in df.columns:\n",
    "        df['Dlib’s HOG + SVM results'] = False\n",
    "\n",
    "    total_images = len(df)\n",
    "\n",
    "    # Process each image in the DataFrame\n",
    "    for idx, row in tqdm(df.iterrows(), total=total_images, desc=\"Running Dlib Portrait Detection\"):\n",
    "        image_path = os.path.join(directory, row['File Name'])\n",
    "        \n",
    "        if os.path.exists(image_path):\n",
    "            portrait_detected = detect_portrait_dlib(image_path)\n",
    "            df.at[idx, 'Dlib’s HOG + SVM results'] = portrait_detected\n",
    "        \n",
    "        if idx % save_interval == 0 and idx != 0:\n",
    "            # Save progress periodically\n",
    "            df.to_csv(df_path, index=False)\n",
    "    \n",
    "    # Save the final updated DataFrame\n",
    "    df.to_csv(df_path, index=False)\n",
    "    print(f\"Dlib portrait detection complete. Results saved to {df_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a2c43c",
   "metadata": {},
   "source": [
    "### 'analyze_portraits_with_dlib' function breakdown\n",
    "---\n",
    "- **`directory`**: This parameter specifies the directory containing the images to be analyzed.\n",
    "\n",
    "- **`df_path`**: This is the file path to the existing DataFrame (CSV file) where the results will be saved.\n",
    "\n",
    "- **`save_interval`**: This optional parameter defines how often the DataFrame should be saved during processing, with the default value set to 100 images.\n",
    "\n",
    "- **Load the existing DataFrame**: \n",
    "  - The function checks if the specified DataFrame file exists at `df_path`. If it does, the DataFrame is loaded using `pd.read_csv(df_path)`. If the file is not found, a `FileNotFoundError` is raised.\n",
    "\n",
    "- **Add a new column for portrait detection results**: \n",
    "  - The function checks if the DataFrame already contains a column named `'Dlib’s HOG + SVM results'`. If not, it adds this column and initializes it with `False` for all rows.\n",
    "\n",
    "- **Process each image in the DataFrame**: \n",
    "  - The function iterates over each row in the DataFrame using `tqdm` to provide a progress bar. For each row, it constructs the full image path using the directory and the `'File Name'` column from the DataFrame.\n",
    "\n",
    "- **Check if the image exists**: \n",
    "  - If the image file exists at the constructed path, the function calls `detect_portrait_dlib(image_path)` to determine if a portrait is detected in the image.\n",
    "\n",
    "- **Update the DataFrame with the detection result**: \n",
    "  - The result (`True` or `False`) is stored in the `'Portrait Detected'` column for the corresponding row in the DataFrame.\n",
    "\n",
    "- **Save progress periodically**: \n",
    "  - The function saves the updated DataFrame to `df_path` after every `save_interval` images have been processed.\n",
    "\n",
    "- **Final save**: \n",
    "  - Once all images have been processed, the function saves the final version of the updated DataFrame to `df_path` and prints a completion message.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf40ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_portraits_with_dlib(directory, df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e459c24e",
   "metadata": {},
   "source": [
    "### File gatherinng function to make model evaluation easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8803319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files_to_new_folder(df, directory, destination_base_dir, folder_name=None):\n",
    "    # Determine the folder name: use provided name, DataFrame's name attribute, or default to \"new_folder\"\n",
    "    if folder_name:\n",
    "        destination_folder = os.path.join(destination_base_dir, folder_name)\n",
    "    elif hasattr(df, 'name') and df.name:\n",
    "        destination_folder = os.path.join(destination_base_dir, df.name)\n",
    "    else:\n",
    "        destination_folder = os.path.join(destination_base_dir, \"new_folder\")\n",
    "    \n",
    "    # Create the folder if it doesn't exist\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    \n",
    "    # Iterate over each file name in the DataFrame\n",
    "    for filename in df[\"File Name\"]:\n",
    "        source_path = os.path.join(directory, filename)\n",
    "        destination_path = os.path.join(destination_folder, filename)\n",
    "        \n",
    "        # Copy the file to the new folder\n",
    "        if os.path.exists(source_path):\n",
    "            shutil.copy(source_path, destination_path)\n",
    "        else:\n",
    "            print(f\"File not found: {source_path}\")\n",
    "    \n",
    "    print(f\"Files have been copied to {destination_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68317fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_files_to_new_folder(df = dlib_true, directory=directory, destination_base_dir=directory, folder_name='dlib_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75282f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ecde4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
