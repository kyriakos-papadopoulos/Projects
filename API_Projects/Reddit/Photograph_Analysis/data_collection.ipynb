{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "152963a9",
   "metadata": {},
   "source": [
    "## Current Progress on Analyzing Components of Successful Photographs\n",
    "\n",
    "1. **Data Collection:**\n",
    "   - **Reddit API:** Successfully implemented the Reddit API to collect top posts from the \"photographs\" subreddit.\n",
    "   - **Metadata Collection:** For each post, we have collected essential metadata such as title, URL, upvotes, comments, and more.\n",
    "   - **Initial Dataset:** A dataset of top posts has been created, with images ready for further analysis.\n",
    "\n",
    "2. **Image Processing and Object Detection:**\n",
    "   - **Object Detection Setup:** Pre-trained models like YOLO and Faster R-CNN have been identified as suitable for detecting objects within the photographs.\n",
    "   - **COCO Dataset Use:** Using the COCO dataset for object detection, focusing on identifying components such as \"person,\" \"car,\" \"tree,\" and other elements commonly found in nature and portrait photographs.\n",
    "   - **Current Focus:** Current efforts are centered on fine-tuning the object detection process to accurately identify relevant components within the images.\n",
    "\n",
    "3. **Data Analysis:**\n",
    "   - **Component Identification:** Preliminary analysis on identifying key components in images (e.g., people, cars, trees) has begun.\n",
    "   - **Engagement Metrics:** The relationship between identified objects and engagement metrics (like upvotes) is being explored to determine what makes a photograph successful.\n",
    "\n",
    "4. **Challenges and Next Steps:**\n",
    "   - **Fine-tuning Object Detection:** Fine-tuning the object detection model to better recognize nuanced components within the photographs (e.g., distinguishing between different types of landscapes or scenes).\n",
    "   - **Handling Diverse Image Content:** Devising strategies to handle the diverse content found in the \"photographs\" subreddit, including nature scenes, urban landscapes, and portraits.\n",
    "\n",
    "5. **Tools and Libraries in Use:**\n",
    "   - **Python Libraries:**\n",
    "      - PRAW for Reddit API interaction.\n",
    "      - OpenCV and Pillow for image processing.\n",
    "      - TensorFlow or PyTorch for implementing and fine-tuning deep learning models.\n",
    "      - Scikit-learn for clustering and other machine learning tasks.\n",
    "      - Matplotlib and Seaborn for data visualization.\n",
    "   \n",
    "   - **Pre-trained Models:**\n",
    "      - YOLO, Faster R-CNN for object detection.\n",
    "      - Potential use of models like VGG16 or ResNet for advanced image classification and embeddings.\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "1. **Refine Object Detection:**\n",
    "   - Continue refining the object detection models to improve accuracy in identifying relevant components within photographs.\n",
    "\n",
    "2. **Expanded Data Analysis:**\n",
    "   - Deepen the analysis of how various components (e.g., presence of people, landscapes) correlate with the success of a photograph on Reddit.\n",
    "\n",
    "3. **Visualization and Reporting:**\n",
    "   - Begin visualizing findings to identify trends and present the relationship between photo components and engagement metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "48408e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import hashlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "796dc462",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv('REDDIT_CLIENT_ID'),\n",
    "    client_secret=os.getenv('REDDIT_CLIENT_SECRET'),\n",
    "    user_agent=os.getenv('REDDIT_USER_AGENT'), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5ccfb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit('photographs')\n",
    "lim = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "028654a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = pd.DataFrame(columns=[\"Date Posted\",\"Title\", \"Content\",\"Comments\", \"URL\", \"Score\"])\n",
    "\n",
    "for post in subreddit.top(limit=lim):\n",
    "    \n",
    "    # Transform timestamp to datetime object\n",
    "    post_date = datetime.utcfromtimestamp(post.created_utc)\n",
    "    \n",
    "    # Ensure all comments are accesible and put them in a list.\n",
    "    post.comments.replace_more(limit=None)\n",
    "    comments_list = [comment.body for comment in post.comments if comment.is_root]\n",
    "    \n",
    "    posts_df = posts_df.append({\n",
    "        \"Date Posted\": post_date,\n",
    "        \"Title\": post.title,\n",
    "        \"Content\": post.selftext,\n",
    "        \"URL\": post.url,\n",
    "        \"Comments\": comments_list,\n",
    "        \"Score\": post.score\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f3d12d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_id(url):\n",
    "    return hashlib.md5(url.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "89ff6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df['Unique ID'] = posts_df['URL'].apply(generate_unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cb3d9ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 998 entries, 0 to 997\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   Date Posted  998 non-null    datetime64[ns]\n",
      " 1   Title        998 non-null    object        \n",
      " 2   Content      998 non-null    object        \n",
      " 3   Comments     998 non-null    object        \n",
      " 4   URL          998 non-null    object        \n",
      " 5   Score        998 non-null    object        \n",
      " 6   Unique ID    998 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(6)\n",
      "memory usage: 54.7+ KB\n"
     ]
    }
   ],
   "source": [
    "posts_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3ec366a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Comments</th>\n",
       "      <th>URL</th>\n",
       "      <th>Score</th>\n",
       "      <th>Unique ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-07 13:24:05</td>\n",
       "      <td>A special moment with my grandfather</td>\n",
       "      <td></td>\n",
       "      <td>[My grandfather had not gotten his picture tak...</td>\n",
       "      <td>https://i.redd.it/g0eolj8mvw961.jpg</td>\n",
       "      <td>2433</td>\n",
       "      <td>976519df32486a271f7a6c4d926541f8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-11 16:13:41</td>\n",
       "      <td>CLOSER</td>\n",
       "      <td></td>\n",
       "      <td>[I have a fascination with close up portraits ...</td>\n",
       "      <td>https://i.redd.it/p10m8ck179n91.jpg</td>\n",
       "      <td>2108</td>\n",
       "      <td>8a923d60029a980d3696765ba8b5bcc8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-21 13:09:30</td>\n",
       "      <td>A barn on a foggy morning in NH</td>\n",
       "      <td></td>\n",
       "      <td>[I took this photo 2 weeks ago in New Hampshir...</td>\n",
       "      <td>https://i.redd.it/9wlc83666gu51.jpg</td>\n",
       "      <td>1999</td>\n",
       "      <td>106210dac14dd2c4dcc1e80e61080652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-25 15:45:39</td>\n",
       "      <td>Birds in the fog.</td>\n",
       "      <td></td>\n",
       "      <td>[I was stuck at the office and saw the fog was...</td>\n",
       "      <td>https://i.imgur.com/BkAh5Cl.jpeg</td>\n",
       "      <td>1820</td>\n",
       "      <td>2f944b4257ea04799dca4a244e507860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-09 11:34:54</td>\n",
       "      <td>Glowing forest mushrooms</td>\n",
       "      <td></td>\n",
       "      <td>[I had a go at something I've seen done a few ...</td>\n",
       "      <td>https://i.redd.it/nsehux7u97y51.jpg</td>\n",
       "      <td>1746</td>\n",
       "      <td>493f732e026330491fa6ca0b2ed56b6c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date Posted                                 Title Content  \\\n",
       "0 2021-01-07 13:24:05  A special moment with my grandfather           \n",
       "1 2022-09-11 16:13:41                                CLOSER           \n",
       "2 2020-10-21 13:09:30       A barn on a foggy morning in NH           \n",
       "3 2022-11-25 15:45:39                     Birds in the fog.           \n",
       "4 2020-11-09 11:34:54              Glowing forest mushrooms           \n",
       "\n",
       "                                            Comments  \\\n",
       "0  [My grandfather had not gotten his picture tak...   \n",
       "1  [I have a fascination with close up portraits ...   \n",
       "2  [I took this photo 2 weeks ago in New Hampshir...   \n",
       "3  [I was stuck at the office and saw the fog was...   \n",
       "4  [I had a go at something I've seen done a few ...   \n",
       "\n",
       "                                   URL Score                         Unique ID  \n",
       "0  https://i.redd.it/g0eolj8mvw961.jpg  2433  976519df32486a271f7a6c4d926541f8  \n",
       "1  https://i.redd.it/p10m8ck179n91.jpg  2108  8a923d60029a980d3696765ba8b5bcc8  \n",
       "2  https://i.redd.it/9wlc83666gu51.jpg  1999  106210dac14dd2c4dcc1e80e61080652  \n",
       "3     https://i.imgur.com/BkAh5Cl.jpeg  1820  2f944b4257ea04799dca4a244e507860  \n",
       "4  https://i.redd.it/nsehux7u97y51.jpg  1746  493f732e026330491fa6ca0b2ed56b6c  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e19ae9",
   "metadata": {},
   "source": [
    "### Dowloading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "af70f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save images.\n",
    "save_dir = f\"{subreddit.display_name}_top_{lim}\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Creating quality variable to standardize the images.\n",
    "image_quality = 85\n",
    "\n",
    "# User-Agent header that mimics a request from a web browser so that the request appears more like a typical web browser request.\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0125afda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing https://i.imgur.com/xRVJlHD.jpg: Image size (188622756 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.\n",
      "Error processing https://www.flickr.com/photos/mloganphotography/50151985597/in/dateposted-public/: Operation on closed image\n",
      "Images downloaded successfully in 1297.02 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "unsuccessful = 0\n",
    "\n",
    "for index, row in posts_df.iterrows():\n",
    "    image_url = row['URL']\n",
    "    unique_id = row['Unique ID']\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(image_url, headers=headers)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            content_type = response.headers.get('Content-Type')\n",
    "            \n",
    "            # Ensure the content is an image\n",
    "            if 'image' in content_type:\n",
    "                image = Image.open(BytesIO(response.content))\n",
    "                \n",
    "                # Handle images in mode P (palette) by converting to RGB\n",
    "                if image.mode == 'P':\n",
    "                    image = image.convert('RGB')\n",
    "                    \n",
    "                # Convert RGBA to RGB if necessary\n",
    "                elif image.mode == 'RGBA':\n",
    "                    image = image.convert('RGB')\n",
    "            \n",
    "            image_filename = f\"{unique_id}.jpeg\"\n",
    "            image.save(os.path.join(save_dir, image_filename), quality=image_quality, optimize=True)\n",
    "            image.close()\n",
    "        else:\n",
    "            unsuccessful += 1\n",
    "            print(f\"Failed to download image from {image_url}\")\n",
    "    except Exception as e:\n",
    "        unsuccessful += 1\n",
    "        print(f\"Error processing {image_url}: {e}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Images downloaded successfully in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e53cef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving df as a pickle file\n",
    "posts_df.to_pickle(\"posts_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0046b1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
